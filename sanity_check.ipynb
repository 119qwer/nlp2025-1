{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed48467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d22aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gpt2 import GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65f30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model as OpenAIGPT2Model\n",
    "from utils import model_size_to_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2e8a2e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_gpt2(model_size='gpt2'):\n",
    "  sent_ids = torch.tensor([[101, 7592, 2088, 102, 0, 0, 0, 0],\n",
    "                           [101, 7592, 15756, 2897, 2005, 17953, 2361, 102]])\n",
    "  att_mask = torch.tensor([[1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "  # OpenAI 모델과 자신의 모델을 모두 로드한다.\n",
    "  openai_model = OpenAIGPT2Model.from_pretrained(model_size)\n",
    "  gpt = GPT2Model.from_pretrained(model=model_size, **model_size_to_params(model_size))\n",
    "\n",
    "  outputs = gpt(sent_ids, att_mask)\n",
    "  openai_outputs = openai_model(input_ids=sent_ids, attention_mask=att_mask, output_hidden_states=True).hidden_states[-1]\n",
    "\n",
    "  att_mask = att_mask.unsqueeze(-1)\n",
    "  outputs['last_hidden_state'] = outputs['last_hidden_state'] * att_mask\n",
    "  openai_outputs *= att_mask\n",
    "\n",
    "  assert torch.allclose(outputs['last_hidden_state'], openai_outputs, atol=1e-1, rtol=1e-2)\n",
    "\n",
    "  print(\"Your GPT2 implementation is correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d95735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your GPT2 implementation is correct!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  test_gpt2('gpt2')\n",
    "# openai_model = OpenAIGPT2Model.from_pretrained('gpt2')\n",
    "# gpt = GPT2Model.from_pretrained(model='gpt2', **model_size_to_params('gpt2'))\n",
    "# openai_model.eval()\n",
    "# gpt.eval()\n",
    "# sent_ids = torch.tensor([[101, 7592, 2088, 102, 0, 0, 0, 0],\n",
    "#                            [101, 7592, 15756, 2897, 2005, 17953, 2361, 102]])\n",
    "# att_mask = torch.tensor([[1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "# outputs = gpt(sent_ids, att_mask)\n",
    "# openai_outputs = openai_model(input_ids=sent_ids, attention_mask=att_mask, output_hidden_states=True).last_hidden_state\n",
    "\n",
    "# att_mask = att_mask.unsqueeze(-1)\n",
    "# outputs['last_hidden_state'] = outputs['last_hidden_state'] * att_mask\n",
    "# openai_outputs *= att_mask\n",
    "# #print(\"OpenAI GPT2 Structure:\")\n",
    "# #print(openai_model)\n",
    "\n",
    "# #print(\"\\nCustom GPT2 Structure:\")\n",
    "# #print(gpt)\n",
    "\n",
    "# # output 형태는 동일\n",
    "# # print(\"\\n\\noutputs.shape:\")\n",
    "# # print(outputs['last_hidden_state'].shape)\n",
    "# # print(openai_outputs.shape)\n",
    "\n",
    "\n",
    "\n",
    "# # 최종 결과 차이 확인\n",
    "# print(\"OpenAI sample value:\", openai_outputs[0, 0, :5])\n",
    "# print(\"Custom sample value:\", outputs['last_hidden_state'][0, 0, :5])\n",
    "# print(\"Diff:\", (openai_outputs - outputs['last_hidden_state'])[0, 0, :5])\n",
    "# # print(gpt.training) \n",
    "# # print(openai_model.training) \n",
    "\n",
    "# #가중치 비교하는 코드인데 문제 없음\n",
    "# # # State dict 얻기\n",
    "# # openai_sd = openai_model.state_dict()\n",
    "# # custom_sd = gpt.state_dict()\n",
    "# # # 키 세트가 일치하는지 먼저 확인\n",
    "# # openai_keys = set(openai_sd.keys())\n",
    "# # custom_keys = set(custom_sd.keys())\n",
    "# # # 1. 키 이름 차이\n",
    "# # only_in_openai = openai_keys - custom_keys\n",
    "# # only_in_custom = custom_keys - openai_keys\n",
    "# # if only_in_openai or only_in_custom:\n",
    "# #     print(\"❗ Key mismatch detected!\")\n",
    "# #     if only_in_openai:\n",
    "# #         print(f\" - Missing in custom: {only_in_openai}\")\n",
    "# #     if only_in_custom:\n",
    "# #         print(f\" - Extra in custom: {only_in_custom}\")\n",
    "# # else:\n",
    "# #     print(\"✅ All keys match.\")\n",
    "# # # 2. 값 비교\n",
    "# # for key in openai_keys & custom_keys:\n",
    "# #     if not torch.allclose(openai_sd[key], custom_sd[key], atol=1e-3, rtol=1e-2):\n",
    "# #         print(f\"❗ Parameter mismatch at key: {key}\")\n",
    "# #         diff = (openai_sd[key] - custom_sd[key]).abs().mean().item()\n",
    "# #         print(f\" - Mean absolute difference: {diff:.5f}\")\n",
    "# #         break\n",
    "# # else:\n",
    "# #     print(\"✅ All parameter values match closely.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8154fa7-a320-439f-909b-4247e9544749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (nlp_final)",
   "language": "python",
   "name": "nlp_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
