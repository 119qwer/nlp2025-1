{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c684a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d20459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSST 과 CFIMDB 위에서 GPT2SentimentClassifier를 훈련하고 평가.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SST 과 CFIMDB 위에서 GPT2SentimentClassifier를 훈련하고 평가.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c168fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np, argparse\n",
    "from types import SimpleNamespace\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e472a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b9a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gpt2 import GPT2Model\n",
    "from optimizer import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6a5b01",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#위 tqdm 라이브러리는 학습 진행 상황을 보여주는 라이브러리인데 TQDM_DISABLE는 그 출력 여부를 나타내는 flag 변수이다.\n",
    "TQDM_DISABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590fc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 시드 값이면 학습 시 같은 결과만 나오기 때문에 당연히 랜덤 시드 설정이 필요함\n",
    "# 필요한 모든 random seed 설정.\n",
    "def seed_everything(seed=11711):\n",
    "  random.seed(seed) # Python의 기본 random 모듈 시드 설정\n",
    "  np.random.seed(seed)  # NumPy의 시드 설정\n",
    "  torch.manual_seed(seed) # PyTorch CPU 연산 시드 설정\n",
    "  torch.cuda.manual_seed(seed) # PyTorch GPU 연산 시드 설정\n",
    "  torch.cuda.manual_seed_all(seed) # 멀티-GPU 환경일 경우 모든 GPU에 대해 시드 설정\n",
    "  torch.backends.cudnn.benchmark = False  # 성능 최적화를 위한 알고리즘 검색 비활성화\n",
    "  torch.backends.cudnn.deterministic = True # 매번 동일한 알고리즘 선택 (완전한 결정론)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7722bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2SentimentClassifier(torch.nn.Module):\n",
    "  '''\n",
    "  이 모듈은 GPT-2를 사용하여 클로즈 스타일(빈칸 채우기) 작업으로 감정 분류를 수행한다.\n",
    "\n",
    "  SST 데이터셋의 감정 범주 = 5 가지(0 - \"부정\"에서 4 - \"긍정\"까지).\n",
    "  따라서, forward() 함수는 5개의 클래스 각각에 대해 하나의 로짓(logit)을 반환해야 한다.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, config):\n",
    "    super(GPT2SentimentClassifier, self).__init__() # 모델 구조를 초기화(안의 데이터를 초기화 하는 것은 아님)\n",
    "    self.num_labels = config.num_labels\n",
    "    self.gpt = GPT2Model.from_pretrained() #우리가 만든 gpt2모델에 사전 학습된 가중치를 이식\n",
    "\n",
    "    # 사전학습 모드에서는 GPT 파라미터들을 업데이트할 필요가 없다.\n",
    "      #assert in은 리스트 안에 값이 있는 지 체크하는 것, \n",
    "      #config.fine_tune_mode가 [\"last-linear-layer\", \"full-model\"] 이 리스트 안에 있으면 통과, 없으면 에러 발생\n",
    "    assert config.fine_tune_mode in [\"last-linear-layer\", \"full-model\"]\n",
    "    for param in self.gpt.parameters():\n",
    "        #gpt-2는 제외하고 classfier만 학습\n",
    "      if config.fine_tune_mode == 'last-linear-layer':\n",
    "        param.requires_grad = False\n",
    "          #gpt-2를 포함한 모델 전체 학습\n",
    "      elif config.fine_tune_mode == 'full-model':\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "    '''\n",
    "    TODO: BERT 임베딩의 감정 분류를 위해 필요한 인스턴스 변수를 생성하시오.\n",
    "    '''\n",
    "    ### 완성시켜야 할 빈 코드 블록\n",
    "    hidden_size = self.gpt.config.hidden_size\n",
    "    self.classifier = torch.nn.Linear(hidden_size, self.num_labels)\n",
    "\n",
    "    \n",
    "      #gpt2는 gpt2_layer를 활용해서 문맥을 학습시킴\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    '''문장들의 batch를 받아서 감정 클래스에 대한 로짓을 반환'''\n",
    "\n",
    "    '''\n",
    "    TODO: 최종 GPT contextualized embedding은 마지막 토큰의 hidden state이다.\n",
    "        힌트: 현재 훈련 반복루프에서 손실 함수로 `F.cross_entropy`를 사용하고 있음을 고려하여\n",
    "        적절한 반환값이 무엇인지 생각해보시오.\n",
    "    ''' \n",
    "    ### 완성시켜야 할 빈 코드 블록\n",
    "      #gpt2는 {'last_hidden_state': sequence_output, 'last_token': last_token} 로 반환하는 데 그 중 last_token이 필요함\n",
    "    outputs = self.gpt(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    last_token = outputs['last_token']\n",
    "    logits = self.classifier(last_token)\n",
    "      #todo에 나오는 손실함수 F.cross_entropy는 softmax 하기 전 값을 주어야 하기 때문에 그대로 logits를 주는 것이 맞다.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e37911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "  def __init__(self, dataset, args):\n",
    "    self.dataset = dataset\n",
    "    self.p = args\n",
    "    self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.dataset[idx]\n",
    "\n",
    "  def pad_data(self, data):\n",
    "    sents = [x[0] for x in data]\n",
    "    labels = [x[1] for x in data]\n",
    "    sent_ids = [x[2] for x in data]\n",
    "\n",
    "    encoding = self.tokenizer(sents, return_tensors='pt', padding=True, truncation=True)\n",
    "    token_ids = torch.LongTensor(encoding['input_ids'])\n",
    "    attention_mask = torch.LongTensor(encoding['attention_mask'])\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    return token_ids, attention_mask, labels, sents, sent_ids\n",
    "\n",
    "  def collate_fn(self, all_data):\n",
    "    token_ids, attention_mask, labels, sents, sent_ids = self.pad_data(all_data)\n",
    "\n",
    "    batched_data = {\n",
    "      'token_ids': token_ids,\n",
    "      'attention_mask': attention_mask,\n",
    "      'labels': labels,\n",
    "      'sents': sents,\n",
    "      'sent_ids': sent_ids\n",
    "    }\n",
    "\n",
    "    return batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c407f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentTestDataset(Dataset):\n",
    "  def __init__(self, dataset, args):\n",
    "    self.dataset = dataset\n",
    "    self.p = args\n",
    "    self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.dataset[idx]\n",
    "\n",
    "  def pad_data(self, data):\n",
    "    sents = [x[0] for x in data]\n",
    "    sent_ids = [x[1] for x in data]\n",
    "\n",
    "    encoding = self.tokenizer(sents, return_tensors='pt', padding=True, truncation=True)\n",
    "    token_ids = torch.LongTensor(encoding['input_ids'])\n",
    "    attention_mask = torch.LongTensor(encoding['attention_mask'])\n",
    "\n",
    "    return token_ids, attention_mask, sents, sent_ids\n",
    "\n",
    "  def collate_fn(self, all_data):\n",
    "    token_ids, attention_mask, sents, sent_ids = self.pad_data(all_data)\n",
    "\n",
    "    batched_data = {\n",
    "      'token_ids': token_ids,\n",
    "      'attention_mask': attention_mask,\n",
    "      'sents': sents,\n",
    "      'sent_ids': sent_ids\n",
    "    }\n",
    "\n",
    "    return batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d592e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드: (sentence, label)의 리스트.\n",
    "def load_data(filename, flag='train'):\n",
    "  num_labels = {}\n",
    "  data = []\n",
    "  if flag == 'test':\n",
    "    with open(filename, 'r') as fp:\n",
    "      for record in csv.DictReader(fp, delimiter='\\t'):\n",
    "        sent = record['sentence'].lower().strip()\n",
    "        sent_id = record['id'].lower().strip()\n",
    "        data.append((sent, sent_id))\n",
    "  else:\n",
    "    with open(filename, 'r') as fp:\n",
    "      for record in csv.DictReader(fp, delimiter='\\t'):\n",
    "        sent = record['sentence'].lower().strip()\n",
    "        sent_id = record['id'].lower().strip()\n",
    "        label = int(record['sentiment'].strip())\n",
    "        if label not in num_labels:\n",
    "          num_labels[label] = len(num_labels)\n",
    "        data.append((sent, label, sent_id))\n",
    "    print(f\"load {len(data)} data from {filename}\")\n",
    "\n",
    "  if flag == 'train':\n",
    "    return data, len(num_labels)\n",
    "  else:\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8790e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev 사례들로 모델을 평가한다.\n",
    "def model_eval(dataloader, model, device):\n",
    "  model.eval()  # Switch to eval model, will turn off randomness like dropout.\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "  sents = []\n",
    "  sent_ids = []\n",
    "  for step, batch in enumerate(tqdm(dataloader, desc=f'eval', disable=TQDM_DISABLE)):\n",
    "    b_ids, b_mask, b_labels, b_sents, b_sent_ids = batch['token_ids'], batch['attention_mask'], \\\n",
    "                                                   batch['labels'], batch['sents'], batch['sent_ids']\n",
    "\n",
    "    b_ids = b_ids.to(device)\n",
    "    b_mask = b_mask.to(device)\n",
    "\n",
    "    logits = model(b_ids, b_mask)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    preds = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "    b_labels = b_labels.flatten()\n",
    "    y_true.extend(b_labels)\n",
    "    y_pred.extend(preds)\n",
    "    sents.extend(b_sents)\n",
    "    sent_ids.extend(b_sent_ids)\n",
    "\n",
    "  f1 = f1_score(y_true, y_pred, average='macro')\n",
    "  acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "  return acc, f1, y_pred, y_true, sents, sent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96d19a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 사례들로 모델을 평가한다.\n",
    "def model_test_eval(dataloader, model, device):\n",
    "  model.eval()  # Switch to eval model, will turn off randomness like dropout.\n",
    "  y_pred = []\n",
    "  sents = []\n",
    "  sent_ids = []\n",
    "  for step, batch in enumerate(tqdm(dataloader, desc=f'eval', disable=TQDM_DISABLE)):\n",
    "    b_ids, b_mask, b_sents, b_sent_ids = batch['token_ids'], batch['attention_mask'], \\\n",
    "                                         batch['sents'], batch['sent_ids']\n",
    "\n",
    "    b_ids = b_ids.to(device)\n",
    "    b_mask = b_mask.to(device)\n",
    "\n",
    "    logits = model(b_ids, b_mask)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    preds = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "    y_pred.extend(preds)\n",
    "    sents.extend(b_sents)\n",
    "    sent_ids.extend(b_sent_ids)\n",
    "\n",
    "  return y_pred, sents, sent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b3a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, args, config, filepath):\n",
    "  save_info = {\n",
    "    'model': model.state_dict(),\n",
    "    'optim': optimizer.state_dict(),\n",
    "    'args': args,\n",
    "    'model_config': config,\n",
    "    'system_rng': random.getstate(),\n",
    "    'numpy_rng': np.random.get_state(),\n",
    "    'torch_rng': torch.random.get_rng_state(),\n",
    "  }\n",
    "\n",
    "  torch.save(save_info, filepath)\n",
    "  print(f\"save the model to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c605259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "  device = torch.device('cuda') if args.use_gpu else torch.device('cpu')\n",
    "  # 데이터와 해당 데이터셋 및 데이터로더를 만든다.\n",
    "  train_data, num_labels = load_data(args.train, 'train')\n",
    "  dev_data = load_data(args.dev, 'valid')\n",
    "\n",
    "  train_dataset = SentimentDataset(train_data, args)\n",
    "  dev_dataset = SentimentDataset(dev_data, args)\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=args.batch_size,\n",
    "                                collate_fn=train_dataset.collate_fn)\n",
    "  dev_dataloader = DataLoader(dev_dataset, shuffle=False, batch_size=args.batch_size,\n",
    "                              collate_fn=dev_dataset.collate_fn)\n",
    "\n",
    "  # Init model.\n",
    "  config = {'hidden_dropout_prob': args.hidden_dropout_prob,\n",
    "            'num_labels': num_labels,\n",
    "            'hidden_size': 768,\n",
    "            'data_dir': '.',\n",
    "            'fine_tune_mode': args.fine_tune_mode}\n",
    "\n",
    "  config = SimpleNamespace(**config)\n",
    "\n",
    "  model = GPT2SentimentClassifier(config)\n",
    "  model = model.to(device)\n",
    "\n",
    "  lr = args.lr\n",
    "  optimizer = AdamW(model.parameters(), lr=lr)\n",
    "  best_dev_acc = 0\n",
    "\n",
    "  for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f'train-{epoch}', disable=TQDM_DISABLE):\n",
    "      b_ids, b_mask, b_labels = (batch['token_ids'],\n",
    "                                 batch['attention_mask'], batch['labels'])\n",
    "\n",
    "      b_ids = b_ids.to(device)\n",
    "      b_mask = b_mask.to(device)\n",
    "      b_labels = b_labels.to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      logits = model(b_ids, b_mask)\n",
    "      loss = F.cross_entropy(logits, b_labels.view(-1), reduction='sum') / args.batch_size\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      train_loss += loss.item()\n",
    "      num_batches += 1\n",
    "\n",
    "    train_loss = train_loss / (num_batches)\n",
    "\n",
    "    train_acc, train_f1, *_ = model_eval(train_dataloader, model, device)\n",
    "    dev_acc, dev_f1, *_ = model_eval(dev_dataloader, model, device)\n",
    "\n",
    "    if dev_acc > best_dev_acc:\n",
    "      best_dev_acc = dev_acc\n",
    "      save_model(model, optimizer, args, config, args.filepath)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train loss :: {train_loss :.3f}, train acc :: {train_acc :.3f}, dev acc :: {dev_acc :.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3274f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args):\n",
    "  with torch.no_grad():\n",
    "    device = torch.device('cuda') if args.use_gpu else torch.device('cpu')\n",
    "    saved = torch.load(args.filepath)\n",
    "    config = saved['model_config']\n",
    "    model = GPT2SentimentClassifier(config)\n",
    "    model.load_state_dict(saved['model'])\n",
    "    model = model.to(device)\n",
    "    print(f\"load model from {args.filepath}\")\n",
    "\n",
    "    dev_data = load_data(args.dev, 'valid')\n",
    "    dev_dataset = SentimentDataset(dev_data, args)\n",
    "    dev_dataloader = DataLoader(dev_dataset, shuffle=False, batch_size=args.batch_size,\n",
    "                                collate_fn=dev_dataset.collate_fn)\n",
    "\n",
    "    test_data = load_data(args.test, 'test')\n",
    "    test_dataset = SentimentTestDataset(test_data, args)\n",
    "    test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=args.batch_size,\n",
    "                                 collate_fn=test_dataset.collate_fn)\n",
    "\n",
    "    dev_acc, dev_f1, dev_pred, dev_true, dev_sents, dev_sent_ids = model_eval(dev_dataloader, model, device)\n",
    "    print('DONE DEV')\n",
    "\n",
    "    test_pred, test_sents, test_sent_ids = model_test_eval(test_dataloader, model, device)\n",
    "    print('DONE Test')\n",
    "\n",
    "    with open(args.dev_out, \"w+\") as f:\n",
    "      print(f\"dev acc :: {dev_acc :.3f}\")\n",
    "      f.write(f\"id \\t Predicted_Sentiment \\n\")\n",
    "      for p, s in zip(dev_sent_ids, dev_pred):\n",
    "        f.write(f\"{p}, {s} \\n\")\n",
    "\n",
    "    with open(args.test_out, \"w+\") as f:\n",
    "      f.write(f\"id \\t Predicted_Sentiment \\n\")\n",
    "      for p, s in zip(test_sent_ids, test_pred):\n",
    "        f.write(f\"{p}, {s} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc6d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\"--seed\", type=int, default=11711)\n",
    "  parser.add_argument(\"--epochs\", type=int, default=10)\n",
    "  parser.add_argument(\"--fine-tune-mode\", type=str,\n",
    "                      help='last-linear-layer: the GPT parameters are frozen and the task specific head parameters are updated; full-model: GPT parameters are updated as well',\n",
    "                      choices=('last-linear-layer', 'full-model'), default=\"last-linear-layer\")\n",
    "  parser.add_argument(\"--use_gpu\", action='store_true')\n",
    "\n",
    "  parser.add_argument(\"--batch_size\", help='sst: 64, cfimdb: 8 can fit a 12GB GPU', type=int, default=8)\n",
    "  parser.add_argument(\"--hidden_dropout_prob\", type=float, default=0.3)\n",
    "  parser.add_argument(\"--lr\", type=float, help=\"learning rate, default lr for 'pretrain': 1e-3, 'finetune': 1e-5\",\n",
    "                      default=1e-3)\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d32b51e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--seed SEED] [--epochs EPOCHS] [--fine-tune-mode {last-linear-layer,full-model}]\n",
      "                             [--use_gpu] [--batch_size BATCH_SIZE] [--hidden_dropout_prob HIDDEN_DROPOUT_PROB]\n",
      "                             [--lr LR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Home\\AppData\\Roaming\\jupyter\\runtime\\kernel-41e2b20d-fe71-4f9c-aa22-4caddeddb097.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\nlp_final\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  args = get_args()\n",
    "  seed_everything(args.seed)\n",
    "\n",
    "  print('Training Sentiment Classifier on SST...')\n",
    "  config = SimpleNamespace(\n",
    "    filepath='sst-classifier.pt',\n",
    "    lr=args.lr,\n",
    "    use_gpu=args.use_gpu,\n",
    "    epochs=args.epochs,\n",
    "    batch_size=args.batch_size,\n",
    "    hidden_dropout_prob=args.hidden_dropout_prob,\n",
    "    train='data/ids-sst-train.csv',\n",
    "    dev='data/ids-sst-dev.csv',\n",
    "    test='data/ids-sst-test-student.csv',\n",
    "    fine_tune_mode=args.fine_tune_mode,\n",
    "    dev_out='predictions/' + args.fine_tune_mode + '-sst-dev-out.csv',\n",
    "    test_out='predictions/' + args.fine_tune_mode + '-sst-test-out.csv'\n",
    "  )\n",
    "\n",
    "  train(config)\n",
    "\n",
    "  print('Evaluating on SST...')\n",
    "  test(config)\n",
    "\n",
    "  print('Training Sentiment Classifier on cfimdb...')\n",
    "  config = SimpleNamespace(\n",
    "    filepath='cfimdb-classifier.pt',\n",
    "    lr=args.lr,\n",
    "    use_gpu=args.use_gpu,\n",
    "    epochs=args.epochs,\n",
    "    batch_size=8,\n",
    "    hidden_dropout_prob=args.hidden_dropout_prob,\n",
    "    train='data/ids-cfimdb-train.csv',\n",
    "    dev='data/ids-cfimdb-dev.csv',\n",
    "    test='data/ids-cfimdb-test-student.csv',\n",
    "    fine_tune_mode=args.fine_tune_mode,\n",
    "    dev_out='predictions/' + args.fine_tune_mode + '-cfimdb-dev-out.csv',\n",
    "    test_out='predictions/' + args.fine_tune_mode + '-cfimdb-test-out.csv'\n",
    "  )\n",
    "\n",
    "  train(config)\n",
    "\n",
    "  print('Evaluating on cfimdb...')\n",
    "  test(config)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (nlp_final)",
   "language": "python",
   "name": "nlp_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
